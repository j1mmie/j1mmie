# 2023
## Dec 28, 3:35pm

First .plan entry on Github. I've maintained a .plan file for a few months now but much of the information is private. I've decided to start a public .plan file to keep track of my progress, help stay motivated, and share the progress of my projects (currently, mainly, Slipstream) with the community.

Most of my .plan writing is stream of consciousness. However, when I am working on a particularly nebulous problem, it helps to write about it more coherently so that I can really wrap my head around it. Today is one of those days:

Today I am continuing work to reorganize our database's datascheme so that it is easier to perform bulk operations on. To do that, I needed to rip out our previous Object Document Mapping (ODM) layer (Typesaurus). Typesaurus hasn't provided much benefit and has in fact hidden some functionality of Firestore.

Firestore's default library is not much better however, so I had to write my own ORM, or ODM, or whatever, to make it easier to work with. Right now its called DocumentProxy, following the naming conventions of Firestore (DocumentReference, DocumentSnapshot, etc). It is not currently following the ActiveRecord design pattern, but I think it should eventually.

The feature that spurred this reorg / refactor is the ability to reward players with XP periodically, outside of battle. The challenges that I faced were:

1. The Firestore API does not support batch-updating across multiple subcollections.

    You can only do batch updates to subcollections on one parent collection.

2. The Firestore client SDK does not provide a way to store data changes in memory.

    You can make data changes to the DB, but then you can't modify the data mapping. So if you want to reserialize a record after you've changed it, you need to fetch it again from the DB. This is by design, and there are reasons for it, but Typesaurus did this and worked fine. So I'm creating a lighter-weight ODM layer similar to Typesaurus, but does not hide the underlying Firestore SDK data.

The reorg / refactor is working locally as far as I can tell. My biggest concerns are:

1. Data integrity

    The Firestore client SDK's set and update methods by default will delete any keys that exist in the DB but aren't included in the payload. In most cases today, I think this is not what I want. But I may have missed or misunderstood the behavior in some parts. So I have to test and make sure that data doesn't randomly go missing.

2. Faults

    The Firestore client SDK's default behavior when a transaction fails is to throw an error. In the Slipstream game and auth servers, these errors must be caught and recovered from. But I must make sure that I've caught all of these instances and that the recovery behavior is well defined.

Aside from the data access layer, I also have some concerns for the feature I'm working on (periodic XP rewards)

3. Recovery

    Ensure that if an XP grant fails, the game server retries granting that same XP so that the player gets their reward eventually.

4. No "double-spend"

    XP received in game should never be rewarded to a player more than once. However, I don't want this to come at the cost of not rewarding players for legitimate XP. So, if it comes to this vs "Recovery", I would favor Recovery.

5. No overlap of reward systems

    There is already a system in the game-servers to reward players with XP after a battle ends. This is not done in bulk, but rather as separate transactions done 1-by-1 asynchronously. I must ensure that XP awarded out of battle does not get counted toward the in-battle reward system. And this must also be true if a reward attempt has failed and is pending retry.

Next steps:

1. Continue testing data reorganization and integrity.
2. Ensure out-of-battle rewards still function as expected
3. Continue working on PendingProgressionRewards system
4. Refactor PostBattleProgressionRewardsProcessor to work with the new batching API, and ensure it can recover from failures

## Dec 29, 3:51pm

Noticed an issue where RPCClient was not properly cleaning up its notification subscriptions when disposed. This caused the client to request all static data N times, where N was the number of times the user re-authenticated per session. It didn't seem to have any side effects, but its resolved.

Back to testing the integrity post-reorg. My plan is to deploy this and migrate data tonight, commandeer Eric and Alfredo to help do regression testing, then continue work on out-of-battle XP once the dust has settled.

## Dec 29, 4:44pm

I'm going to take a break from regression testing and focus on shoring up the new usage of Firestore client SDK. Will be testing:

1. When set/update/add/delete methods throw, errors are caught elegantly and game server continues functioning
2. Make sure Firestore client SDK has built in retries when a failure happens. This was happening before (as evidenced by my logs), but I'm not sure it was provided by Typesaurus or the underlying SDK. Hoping it's built into the SDK

Now how do I turn on those internal logs again...

--

Here's what I found: It's possible that the DB client has a built-in retry w/ debounce. The *functions* client does not. Previously, I manually added a debounce for every function call. I've now refactored ServiceFunctionClient to include the debounce by default, and hidden the internals of that in ServiceFunctionClientInternal. ServiceFunctionClient will be used for adding / remove / interacting with functions in the future. All internals are abstracted away.

Also, it looks like these are the services that get called from the client:
  1. checkIn (apps/game/src/App.ts)
  2. gameSessionUpdate (apps/game/src/game-lift/GameLiftBootstrapper.ts)
  3. grantCrewmatePostBattleWinnings (apps/game/src/battle/battle-results/PostBattleProgressionRewardsProcessor.ts)
  4. grantCrewmatePostCampaignWinnings (apps/game/src/campaigns/campaign-results/PostCampaignProgressionRewardsProcessor.ts)

6pm - Weekly Demos meeting:

TODO: ShipTechLevelChanged Notif should include latest gem economy changes so that in-ship gem display counters can decrement when tech is upgraded.

9:37pm

Regression test looks good. Good enough for deploy + data migration. Merging this work into main and deploying

- [x] Deploy new code - Success
- [x] Run migrations dry run (`npm run migrations:production:migrate:dry`) - Success set:782 deleted:782
- [x] Run migrations dry production (`npm run migrations:production:migrate:commit`) - Success? set:782 deleted:782
- [x] Redeploy auth and dev1 game servers

Everything seems to have gone fine. However, I've just learned that Retool cannot do "complex" queries like finding a record by a reference's value. So you can't do like, `SELECT * FROM crew WHERE user = "users/abc123"`.

TODO: Redeploy to Gamelift

Notice a problem in the prod Auth server. Apparently Firestore uses Timestamp objects instead of Date objects. And elsewhere in the auth code I saw POJSOs that looked like `{ "_seconds": 999, "_nanoseconds": 999 }`. Not sure in which situation these timestamps are numbers, string, Dates, Timestamps, or generic objects, but I wrote a helper to convert them. I should really narrow that down to avoid data corruption

# 2024
## Jan 3, 1:19pm

Been quietly working on tests for the BackgroundProgressionRewardManager. I've got some basic tests there that don't test the worst edge cases, but give me reasonable confidence in it. Now I'm writing tests for the Firebase functions side of things - `getPartialForCrewmateXpGrant` now, and later `serviceGrantMultipleCrewmatesXpHandler`

Randomly thought of a way to express my thoughts on styling for comments:

1. Single-line comments should not go past the 100 character column
2. Multi-line comments should not go past the 80 character column

Examples:

```
                                                              80 char column \                     / 100 char column
                                                                              |                   |
# INCORRECT:                                                                  |                   |
# This is a line that is longer than 80 chars but the resulting new line looks|                   |
# weird                                                                       |                   |
                                                                              |                   |
# Correct:                                                                    |                   |
# This is a line that is longer than 80 chars but the resulting new line looks weird              |
                                                                              |                   |
# INCORRECT                                                                   |                   |
# Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla euismod, nisl eget aliquam ultricies, nunc nisl ultricies nunc, quis aliquam ni
                                                                              |                   |
# INCORRECT                                                                   |                   |
# Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla euismod, nisl eget aliquam ultricies
                                                                              |                   |
# Correct                                                                     |                   |
# Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla euismod, nisl|                   |
# eget aliquam ultricies                                                      |                   |
                                                                              |                   |
# INCORRECT                                                                   |                   |
# Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla euismod, nisl eget aliquam       |
# ultricies, nunc nisl ultricies nunc, quis aliquam ni                        |                   |
                                                                              |                   |
# Correct                                                                     |                   |
# Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla euismod, nisl|                   |
# eget aliquam ultricies, nunc nisl ultricies nunc, quis aliquam ni           |                   |
```

This is such a stupid thing to be thinking about. I've just always felt like some comments (and code) are okay to go past the agreed upon column limit if the resulting line break actually makes the comment / code less readable. A few dangling words on a line of their own are distracting imo

Back to work.

3:24pm

Tests done. Now to test manually. But there's a 3:30 planning meeting coming up first

Planning meeting notes:
 - Apple SignIn is the next big ticket item for me

Back to manually testing. So far I discovered one bug where XP rewards are successfully granted, but the game server fails to parse the response correctly. In that case, the rewards stay in the processing queue and get granted once again. This isn't an issue if the function server + game server agree on the successful response data's shape, but in the odd event that they don't, I want to handle this case.

11:10pm

Background XP rewards are officially working end-to-end locally. The client receives a notif any time XP goes up, and animated the hud accordingly. As well as renders level changes and the skill points available UI when a level up occurs. One bug - The dialog where one would spend skill points doesn't actually show any as available when it loads. How this is possible, I do not know...

## Jan 4, 10:37am

Finished Background XP rewards end-to-end. Merged, deployed. Eric tested a bit, no major bugs. Today I will do a bit more cleanup, and do more testing around downtime / network issues. Then I would like to refactor `PostBattleProgressionRewardsProcessor` to work in batches. Oh, and I broke `cheatGrantCrewmateXpHandler`, or at least the way the client uses it. Will fix that.

This morning I made a diagram to help communicate the game's front-end architecture a bit more. 1. Because Alfredo will do some of the work for simulating a game-server locally (more on that later), and 2. Because in one of his PR's I noticed some concern-crossing. I was able to easily spot the concern-crossing and needed to explain how others would be able to do it. Hence this diagram:

![](assets/slipstream-client-architecture.png)

Back to work.

1:45pm

TODO: Investigate speeding up CloudDBClient#GetDocById. Could append .json to URL to let DB do JSON conversion for me (so client doesn't have to)

Currently creating some automation for my test suite. Automatic user and service-account signin. Using a new tool, Insomniac - a replacement for Postman. Pretty good so far.

Using Insomniac, I set up an Environment (Slipstream Local) that automatically logs in as a user or service-account. I created to demo endpoints - serviceGetCrewByUserId and cheatGrantCrewmateXp. For former signs in as the service-account. The latter signs in as whatever user is in the environment field `twitchUserName`. Very cool

Back to fixing `cheatGrantCrewmateXpHandler` - I fixed that locally. It was a client-side issue. I should be able to connect to dev1 now and try again without needing to deploy new code to firebase prod or dev1.

Yup, that worked. Committing.

## Jan 5, 3:51pm

Demos meeting. Group testing background XP rewards. Looks good except there's a good amount of floating point precision error. Would be great to get that fixed but Eric's not too worried.

Found a bug where skill points that were available go missing (on the client). Database seems correct but the client is overwriting the value with something that's cached or something.

Also the score multiplier is wrong. It should be .05 of the score for the particular stat. The multiplier is BattleRewardsConstants.BattleScoreXpRatio. Fixed

--

Yesterday I started working on Apple SignIn. Managed to get a development build to work with Apple SignIn entitlement, added the open-source Unity Apple SignIn framework to the game, and was able to generate an Apple JWT. Now I've got to deliver that JWT to the auth server at a yet-to-be created endpoint. Create a generic account (with randomly generated name I guess)

## Jan 8, 3:15pm

Before continuing work on Apple SignIn today, I looked into upgrading our server stack to Node18. Firebase is dropping support for Node16 (Released on Oct 20, 2020. LTS version Apr 20, 2021), but Amazon Linux 2 on GameLift only supports Node16. It looks like Amazon Linux 2023 supports Node18 (Released Apr 20, 2022. Via the dnf package manager). So I believe I'll be able to upgrade Firebase and GameLift to Node 18. I guess Node 20 (Released Apr 19, 2023) is too much to ask for?

Back to Apple SignIn.

Apple SignIn is an absolute mess. I'm saving notes in another markdown file.

## Jan 11, 11:15am

My understanding of Apple SignIn has improved. I've managed to get it working for new users. A barebones user gets created for them on initial login (just like Twitch auth). I've scoured the codebase to replace all usage of TwitchID and TwitchUsername where appropriate (Captains still require Twitch auth).

So next up on my agenda is:
1. [ ] Implement refresh tokens for Apple SignIn (in progress)
2. [ ] Implement [Quick login](https://github.com/lupidan/apple-signin-unity#quick-login) before attempting a fresh signin
3. [ ] Refactors. Client: OAuthSigninController should be renamed to AuthUIController, Twitch logic should be broken out into a separate module, same for AppleSignIn. AuthUIController should react to events from those child objects. Server: Similarly, Apple and Twitch should be broken out into modules if their concepts are similar enough (I *think* they are).
4. [ ] Regression testing, specifically for Twitch / Twitch auth / expiration

We have a Dev stream coming up in about 5 hours. Eric will be showing off some of the new stuff in game.

Even without the dev stream, I think this will be 2 more days of work. I'll make some headway on items 1 and 2 today. But refactoring and regression testing will most likely be longer. It would be pretty awesome if I were done tomorrow!

One point of frustration that I've been battling with - my 2019 Macbook is becoming painfully slow. Specifically when I have 4 VSCode projects open (Client, Game Server, Auth Server, Firebase), Unity, XCode, iOS Simulator. We don't really have the budget for the laptop I'd like, and opting for a mid-tier upgrade seems like a waste. But if it impedes development enough, it might be worth it to upgrade.

Wishlist item: \
    [MacBook Pro M3 Max](https://www.apple.com/shop/buy-mac/macbook-pro/16-inch-m3-max) \
    16 inch screen \
    16-core CPU \
    40-core GPU \
    48GB Unified Memory \
    1TB SSD Storage \
    Last refreshed October 2023 \
    **$4000**

That reminds me - good time to back up my system. This laptop could blow up any day now.

## Jan 12, 2:59pm

Apple Sign In is merged into main and was deployed to dev1 / prod. I've tested the basic flow, it works fine. I just realized though that there can now potentially be two users with the same email address in the database. I'm wondering if that's okay or not. We don't use the email address as a unique identifier in any way, so maybe it's okay.

Time for our weekly demos meeting.

## Jan 19, 3:58pm

I spent the week working on small client bugs. Switching back to Auth to handle merging Twitch + Apple sign in data.

The idea is to favor Twitch auth information, but keep keychain data for both Auth methods so that the user can henceforth choose which auth method they want to use. Once a user signs in with Twitch, they inherit the Twitch DisplayName, Profile Pic, and Email Address. We'll use email address as an identifier to determine if its the same user.

## Jan 22, 11:10am

Taking a break on the Apple Sign In account merging thing. I had trouble focusing on it last week, for personal reasons. This week I'm going to focus on App Store approvals and launch stuff (trailer, media, etc). Today, I'm going to get Game Lift up and running with the latest code, *hopefully* on the latest version of Linux. I am going to test upgrading to Amazon Linux 2023 and Node 18.

I looked into using Amazon Linux 2023. Ran into a problem: Amazon Linux 2023 requires GameLift Server SDK 5.0.0. We're using a bootleg version of the Server SDK that was ported to Node, and I believe it was targetting Server SDK version 3.2.1 (according to this line of code: https://github.com/j1mmie/GameLift-Nodejs-ServerSDK/blob/0c6d64a98d68bab65927d0b03a7237e631b7ba8a/src/Server/GameLiftServerAPI.ts#L14). To add to the confusion, we've been using Server SDK 4.0.2 in our "production" servers during alpha testing, and that's worked fine. So one question is, was the change from 3.2.1 to 4.0.2 so subtle that it didn't break much? (It broke some stuff, I think. That's why I forked dplusic's branch above). Maybe the change from 4.0.2 to 5.0.0 is equally subtle? I know Amazon GameLift now supports "GameLift Anywhere", which our Server SDK does not understand. But it might be possible to easily modify our bootleg fork to support 5.0.0 features.

Before I do any porting, I need to get production servers online for our launch. I'm going to switch back to Amazon Linux 2 and see if I can get Node 18 running on that. Seems unlikely though, in which case we'll have to switch back to Node 16. Another painful realization: [Amazon Linux 2 End of Life is 2025-06-30](https://aws.amazon.com/amazon-linux-2/faqs/) :( So we have < 1.5 years to come up with a long term solution. Agones + Kubernetes looking really compelling right about now. Supports node out of the box: https://agones.dev/site/docs/guides/client-sdks/nodejs/

Node 16 is not ideal because Firebase is phasing it out. Ideally all of the server projects use the same version of Node - I'd prefer not to support Node 16 for GameLift and Node 18 for Firebase. ugh.

4:30pm

Good news, I found a version of Amazon Linux 2 that is used by Elastic Beanstalk that supports Node 18.19.0. It was a bit of a hack to find it [see discussion here](https://github.com/nodesource/distributions/issues/1381), and I don't know if Amazon will be publically supporting these builds *outside* of Beanstalk. But it works, and providing a binary for Amazon Linux 2 is already my workflow. So... I guess let's use it? What's the worst that could happen.

I've tested Firebase, Auth, and Game in Node 18. Things are looking good. I'm now going to make sure the GameLift deploy scripts are in order, and attempt a deploy.

6:19pm

Production servers went live without much trouble. The game client is running into an error when trying to deserialize GameSessions - likely introduced when I got rid of Typesaurus. Two problems: 1. The Firebase functions getMySessions and getSessions are not serializing documents to the expected format. 2. GameSessionModel is using Dates, not Timestamps.


11:35pm

Fixed the API issues (both client and server have been updated to support eachother).

Tomorrow I need to:
 - Simulate a long response time for "startGameSession" - UI should behave appropriately
 - Add support for feature flags
 - Add a boolean feature flag that allows anyone to launch a ship
 - Add a string feature flag that tells the client which version of the API its using

## Jan 25, 1:14pm

I've added feature flags to the DB. Right now the client pulls them after signin. Also, they're not cached in any way. So my tasks are:

1. Move feature flag retrieval to the title screen. This way, we can determine if the game is in maintenance mode and if the client has the right API version quickly.
2. Implement the maintenance mode feature flag
3. Implement the API version feature flag
4. Add caching (possibly using https://firebase.google.com/docs/firestore/bundles, https://extensions.dev/extensions/firebase/firestore-bundle-builder)

2:13pm

Took a brief detour to enable automated DB backups in Firebase. These are my findings:

--

Two backup schedules have been created:

1. Nightly, retained for 7 days
2. Weekly on Monday, retained for 14 weeks

The schedules are retrievable via the command line:

```
➜  git:(main) ✗ gcloud alpha firestore backups schedules list --database='(default)'
---
createTime: '2024-01-25T22:08:30.917453Z'
name: projects/PROJECT_NAME/databases/(default)/backupSchedules/64379432-9965-4cd7-b4d1-25079051e7d6
retention: 8467200s
updateTime: '2024-01-25T22:08:30.917453Z'
weeklyRecurrence:
  day: MONDAY
---
createTime: '2024-01-25T22:01:27.982275Z'
dailyRecurrence: {}
name: projects/PROJECT_NAME/databases/(default)/backupSchedules/4bdc6324-afbb-4d03-899e-921a03ee1d5b
retention: 604800s
updateTime: '2024-01-25T22:01:27.982275Z'
```

Backups can be listed with the following command, but none exist yet:

```
➜  git:(main) ✗ gcloud alpha firestore backups list
Listed 0 items.
```


You can restore backups to a different DB for debugging purposes. For example:

```
gcloud alpha firestore databases restore \
--source-backup=projects/PROJECT_NAME/locations/LOCATION/backups/BACKUP_ID
--destination-database='MY_RESTORATION_DATABASE'
```

^ If MY_RESTORATION_DATABASE already exists (I believe)



More info on how backups work here:

https://cloud.google.com/firestore/docs/backups

--

## Jan 29, 6:18pm

Creating a caching layer for static data that is in our database. I'm using Google Cloud Storage for this. So far PlatformConfig is working. TODO:

1. Update StaticData Svc on the frontend to use this service
2. Create a StaticDataManager that can be used by Functions, Auth, and Game that caches this data in memory
3. Create a good workflow for publishing changes

## Jan 30, 12:16pm

I'm currently dealing with some extended Jury Duty so work has been a bit slow.

I'm working on converting the StaticData Svc to use these new cached JSON files. I realized that cache busting might still be a problem using Google Cloud Storage. So I'm going to look into Firebase Remote Config to see if I can store a version number for the JSON bundles. The idea is:

1. Client checks Remote Config for JSON bundle version #
2. Client determine whether it needs to download new static data
   1. Yes: Download
   2. No: Assume downloaded

When we want to publish new JSON bundles, we have a script that performs these operations:

1. Get Remote Config for latest version number
2. Increment version number
3. Generate bundles
4. Save in some folder like /json-bundles/{version}/{collection}.json
5. Save the new Remote Config

The hope is that Remote Config is not as expensive as a Firestore request, and it the cache will be busted when the config is changed. Then we don't have to worry about caching policies with the particular bundle version - the version number will change and be guaranteed to be a new file.

Confirmed: Remote Config is free.

--

Hit a snag - Remote Config has some limitations. For one, there is throttling (per user, 5 reads / hour). Secondly, Remote Config data expires every 90 days. So instead, I'll publish the JSON bundle version number to the platformConfig collection. We'll incur an additional read DB read every so often from our users. But it saves us the dozens of reads per user we're doing currently and reduces dependencies / complexity.

--

## Jan 31, 10:38pm

Static data caching layer is going well. The client fetches platformConfig to determine the latest static data version. It then fetches a copy of the static data from Firebase Storage. It saves that copy to the disk so that it may pull from the disk if the version number hasn't changed.

Next up is to get the servers to use static data instead of live data. This is important so that changes to the static data before they're published don't accidentally get used by the server side.

## Feb 1, 3:16pm

I'm working on a static data manager for the auth and game servers. One potential issue is that the auth server doesn't know when new data has been published. We'll either need to manually restart it, or build that into the publishing process. Alternatively, we could refresh the static data every hour or so. But that kind of obfuscates the issue and could potentially lead to more confusion. I think we'll build it into our manual deploy plan to restart auth when necessary.

Learning: I discovered that the Firestore client DOES have built in retry capability in case a document read fails.

Learning: The Firebase Storage client SDK does not retry, at least in the event of a "not found" error. Might have to add my own exponential backoff to that.

6:36pm

I've updated the server StaticDataManager to pull all static data at startup. Next up, I should test to ensure that SectorCompletionLogic is still functioning as expected. The Captain should get the appropriate Economy rewards after completing a sector.

Otherwise, static data isn't used elsewhere much. I think I'll need to add PlatformConfigManager and StaticDataManager to the functions project, so that functions can used cached data as well. That means I'll need to move PlatformConfigManager and StaticDataManager to @slipstream/core. I should also make it so that it doesn't fetch static data until it's requested. I'll also need to think about caching static data in a Google Function, and busting that cache when new data is published. All of this is too much to think about - maybe I just punt it. Ugh

## Feb 4, 2:30pm

I've done the above. StaticDataManager and PlatformConfigManager are now in @slipstream/core. I've created a new class for functions/lambdas - LazyStaticCollection, which manages downloading cached data and storing in memory for the duration of the container's life. I've converted over all usage of static data in functions to lazy static collections.

Next I must do some manual testing and write more tests.

Features to test:
 - GrantCrewmateXp (Post-battle XP grants)
 - GrantMultipleCrewmatesXp (Out-of-battle XP grants)
 - UnlockCrewmate
 - UpgradeCrewmateStat
 - Sector Cleared rewards

THEN:

1. [ ] Make clients refresh platformConfig on restart, and react to changes in `maintenanceMode` and `currentApiVersion` accordingly. Apparently `staticDataBundleVersion` already triggers new static data bundle downloads.

2. [x] Fix multi-gem pickup bug

## Feb 5, 9:18am

TODO: Research @nx/js:tsc generateExportsField

12:09pm

generateExportsField doesn't do anything

I reorganized the Nx project to have fewer dependencies (using nx's implicitDependencies feature). Looks like we shaved off a lot for functions deploys. Maybe that means faster deploys + warmup times?? The dependency graph, visualized, is MUCH cleaner. I'm just concerned that I've broken something that's not obvious.

4:33pm

Added Maintenance Mode and API Versioning to both client and servers, including Functions. Need a way for Admins to punch through the versioning. ALso need to make sure that services are automatically punched through.

11:12pm

Explore using Environment variables to clear platformConfig and staticLazyCollection caches, in functions. https://stackoverflow.com/questions/75839352/is-there-a-way-to-restart-running-instances-of-firebase-functions-gcloud-functi


